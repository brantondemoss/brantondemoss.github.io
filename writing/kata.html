<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>kata.md – kata</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="github.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="love-letter-to-katago-or-go-ai-past-present-and-future">Love Letter to KataGo, or: <br> Go AI past, present, and future</h1>
<p><img src="katagame.png" /> <em>KataGo (B) vs LeelaZero (W)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></em></p>
<blockquote>
<p>In order to programme a computer to play a reasonable game of Go - rather than merely a legal game - it is necessary to formalise the principles of good strategy, or to design a learning programme. The principles are more qualitative and mysterious than in chess, and depend more on judgment. So I think it will be even more difficult to programme a computer to play a reasonable game of Go than of chess. <br>- I J Good, 1965<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</blockquote>
<p>There’s something magical about the game of Go. For thousands of years, it has captured the imagination of those who want to learn <em>what it is to learn</em>, to think about what thinking means.</p>
<p>With the recent advent of strong, open source Go AI that can beat top professionals, it’s worth tracing the histroy of the game, why it remained so difficult to beat humans for so long, and what the future of Go may hold.</p>
<h2 id="complexity">Complexity</h2>
<p>Like chess, Go is a deterministic game of perfect information. There is no stochasticity, no hidden state.</p>
<p>Unlike chess in which there are on average around 35 legal moves to consider playing each turn, there are on average around 250 legal moves to consider in Go.</p>
<p>In tic-tac-toe, we can search the entire game tree, and easily find the optimal response at any state. xkcd nicely summarized this in an image:</p>
<p><img src="xkcd.png" /> <em>Perfect <span class="math inline">\(\times\)</span> strategy<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></em></p>
<p>Although it is in principle possible to create such a tree for Go since it is a finite game, the state space of Go is very large: the number of legal positions<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> in Go is approximately <span class="math inline">\(2.1 \times 10^{170}\)</span>.</p>
<p>Since a game is a trajectory through legal board states, the number of possible games of Go is considerably larger. The number of unique games of Go has been bounded between <span class="math inline">\((10^{10^{104}},10^{10^{171}})\)</span> <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>
<h2 id="intuition-reading">Intuition &amp; Reading</h2>
<p>Go’s state space is too larged to be searched, because of this players must learn to prune bad moves, focusing only on moves that look promising - players must develop an <em>intuitive</em> sense of what moves might be good, and avoid wasting time on dubious possibilities.</p>
<p>While intuition guides move selection, reading strengthens intuition with a form of self-argument. With a set of move candidates, players must read ahead, considering how their opponent will respond to maximise their <strong>own</strong> chance of winning. Reading can involve considering up to dozens<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> of moves and responses, evaluating which player gets a “better” result in the end.</p>
<p>Intuition and reading lie at the center of Go’s connection with creativity and intelligence. One must consider the board from an opponent’s perspective, develop an intuition for favorable positions that will lead to victory, and consider long chains of state transitions where the opponent will try to gain advantage. Consider how hard it really is to chose a move when you know the opponent’s response will be designed to steal the advantage from you. It is not a straight and clear path.</p>
<p>How can we encode all of these properties into computers? How can we give AI intuition for promising moves, reading capability, and most importantly, creativity?</p>
<h2 id="creativity">Creativity</h2>
<p>Before we can even consider giving AI creativity, we have to try to define what creativity even is.</p>
<p>Creativity is fundamentally related to our own ignorance. If a problem has a known solution, implementing it is not considered creative. It is rather the <em>surprisingness</em> of the solution that determines how creative we consider it.</p>
<p>If you accept this position, then creativity and novelty are closely linked. To make a creative AI Go player, we require it to be able to find <em>new</em> ways of playing. Unlike the AI systems of old<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>, we want our Go AI to discover new knowledge on its own, and share it with us.</p>
<h2 id="classical-ai">Classical AI</h2>
<p>Expert knowledge systems, DeepBlue, value function definition problems</p>
<p>Tree search, alpha-beta and MCTS</p>
<p>Early MCTS bots</p>
<p>Value of position is percent of playouts from position which result in winning state</p>
<h2 id="alphago">AlphaGo</h2>
<p>Bootstrapping from human knowledge</p>
<p>Reinforcement learning def and cartoon</p>
<p>AlphaZero - no additional features. Combining policy and value in backbone strength increase (eye towards KataGo implementing additional outputs as regularizers)</p>
<p>Strength of policy + reading. Elo ratings</p>
<h2 id="leela-zero">Leela Zero</h2>
<p>Troubles with ladders</p>
<p>Compute efficiency</p>
<p>Open source ethos, reproducability, incorporating ELFv2 games, bringing AI review to the masses</p>
<p>Shin Jinseo reportedly uses Leela on an iPad everywhere</p>
<p>Loss to FineArt (jueyi) in AI cup</p>
<h2 id="katago">KataGo</h2>
<p>Reinforcement + Features + Self Supervised (additional training signal)</p>
<p>Arbitrary board sizes and komi - helpful for public to learn</p>
<p>Igo Hatsuyoron</p>
<p>Compute efficiency</p>
<p>Continuing development</p>
<p>Speculation about future research directions</p>
<p>David Silver quote Zero bots will continue to get better for 100 years with more compute</p>
<p>How can we make AI bots more useful to humans to elarn from and study with? Will they overfit to MCTS policy and become overconfident?</p>
<p>MuZero Go RL “model” learned in NN</p>
<p>Interview Q’s w/DJ Wu?</p>
<h2 id="other-bots">Other Bots</h2>
<p>Black hole? Q-whatever minigo</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="http://www.yss-aya.com/cgos/viewer.cgi?19x19/SGF/2020/05/14/693137.sgf">KataGo vs. Leela Zero</a>: B+Resign<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="http://www.chilton-computing.org.uk/acl/literature/reports/p019.htm">I J Good: The Mystery of Go, 1965</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><a href="https://xkcd.com/832/">xkcd 832</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><a href="https://tromp.github.io/go/legal.html">Tromp: Number of legal Go positions</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Lower bound: <a href="GoGamesNumber.pdf">Walraet: A Googolplex of Go Games</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Upper bound: <a href="https://tromp.github.io/go/gostate.pdf">Tromp and Farneback: Combinatorics of Go</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>At least in the case of ladders<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p><a href="https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov">Deep Blue vs. Kasparov</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
